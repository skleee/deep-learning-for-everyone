{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"01_First_Deep_Learning.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"eI9cXO16zHcL","colab_type":"code","outputId":"1aec3f7e-26ac-4ec4-96a7-6401e7ca46b1","executionInfo":{"status":"ok","timestamp":1584879762030,"user_tz":-540,"elapsed":583,"user":{"displayName":"성균관대이선경","photoUrl":"","userId":"02440799744141595633"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vhn40Y4B0ztg","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OtYUA2e0ztCP","colab_type":"code","outputId":"7e438be8-5c1a-41e6-fbde-53a0a4dcbac8","executionInfo":{"status":"ok","timestamp":1584879771293,"user_tz":-540,"elapsed":1718,"user":{"displayName":"성균관대이선경","photoUrl":"","userId":"02440799744141595633"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# TF 2.0 must be installed manually as the default version of TF in Colab is yet 1.15.0.\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R0-1OO-jP5pi","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZkKTmAcQP_Th","colab_type":"code","colab":{}},"source":["# 실행할 때마다 같은 결과를 출력하기 위해 설정\n","np.random.seed(3)\n","tf.random.set_seed(3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"blETu5HLQeRS","colab_type":"code","colab":{}},"source":["# 수술 환자 데이터 불러오기\n","Data_set = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/deep-learning-for-everyone/dataset/ThoraricSurgery.csv\", delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGLdNH7LTbaS","colab_type":"code","colab":{}},"source":["# 환자 기록과 수술 결과를 각각 X, Y에 저장\n","X = Data_set[:,0:17] # each row in the 0:17(1st~17th) column\n","Y = Data_set[:,17] # each row in the 18th column"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxQNKUYHT853","colab_type":"code","colab":{}},"source":["# 딥러닝 구조 결정 (모델을 설정하고 실행하는 부분)\n","# model.add()로 새로운 층 형성. 맨 마지막 층은 출력층, 나머지는 은닉층의 역할을 함\n","# Dense()로 구체적인 구조 결정\n","model = Sequential()\n","###### [은닉층] ######\n","# 첫 파라미터는 노드 개수(30)\n","# input_dim: 입력 데이터에서 몇 개의 값을 가져올지 결정하는 변수(17) -> 데이터에서 17개 값을 받아 은닉층의 30개 노드로 보낸다는 뜻.\n","# (Keras는 입력층을 따로 만드는 것이 아니라, 첫 은닉층에 input_dim을 적어줌으로써 첫 번째 Dense가 은닉층과 입력층의 역할을 겸함.)\n","# activation: 활성화 함수 설정\n","model.add(Dense(30, input_dim=17, activation='relu')) \n","###### [출력층] ######\n","model.add(Dense(1, activation='sigmoid')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwVGQ7Z0UDrS","colab_type":"code","outputId":"9990fa13-1fa0-4903-dd6a-a5af8f4cb5d1","executionInfo":{"status":"ok","timestamp":1584879787315,"user_tz":-540,"elapsed":8280,"user":{"displayName":"성균관대이선경","photoUrl":"","userId":"02440799744141595633"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 모델 컴파일\n","# loss: 오차함수 설정 (e.g. mean_squared_error, binary_crossentropy etc)\n","# optimizer: 최적화 방법 선택\n","# metrics(): 모델이 컴파일 될 때 모델 수행 결과 나타냄. 정확도를 측정하기 위해 사용되는 테스트 샘플을 학습 과정에서 제외함으로써 과적합 문제 방지.\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","\n","# 모델 실행\n","# epoch (학습 프로세스가 모든 샘플에 대해 한 번 실행되는 것을 1 epoch)\n","# batch_size: 샘플 한 번에 몇 개씩 처리할지. 적당히.\n","model.fit(X, Y, epochs=100, batch_size=10)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Train on 470 samples\n","Epoch 1/100\n","470/470 [==============================] - 1s 1ms/sample - loss: 0.1495 - accuracy: 0.8404\n","Epoch 2/100\n","470/470 [==============================] - 0s 155us/sample - loss: 0.1447 - accuracy: 0.8511\n","Epoch 3/100\n","470/470 [==============================] - 0s 172us/sample - loss: 0.1448 - accuracy: 0.8511\n","Epoch 4/100\n","470/470 [==============================] - 0s 170us/sample - loss: 0.1453 - accuracy: 0.8489\n","Epoch 5/100\n","470/470 [==============================] - 0s 150us/sample - loss: 0.1438 - accuracy: 0.8511\n","Epoch 6/100\n","470/470 [==============================] - 0s 142us/sample - loss: 0.1418 - accuracy: 0.8511\n","Epoch 7/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1425 - accuracy: 0.8511\n","Epoch 8/100\n","470/470 [==============================] - 0s 159us/sample - loss: 0.1427 - accuracy: 0.8468\n","Epoch 9/100\n","470/470 [==============================] - 0s 161us/sample - loss: 0.1446 - accuracy: 0.8489\n","Epoch 10/100\n","470/470 [==============================] - 0s 141us/sample - loss: 0.1427 - accuracy: 0.8511\n","Epoch 11/100\n","470/470 [==============================] - 0s 165us/sample - loss: 0.1429 - accuracy: 0.8511\n","Epoch 12/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1419 - accuracy: 0.8511\n","Epoch 13/100\n","470/470 [==============================] - 0s 152us/sample - loss: 0.1424 - accuracy: 0.8489\n","Epoch 14/100\n","470/470 [==============================] - 0s 159us/sample - loss: 0.1431 - accuracy: 0.8489\n","Epoch 15/100\n","470/470 [==============================] - 0s 144us/sample - loss: 0.1422 - accuracy: 0.8404\n","Epoch 16/100\n","470/470 [==============================] - 0s 150us/sample - loss: 0.1405 - accuracy: 0.8511\n","Epoch 17/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1390 - accuracy: 0.8489\n","Epoch 18/100\n","470/470 [==============================] - 0s 157us/sample - loss: 0.1398 - accuracy: 0.8383\n","Epoch 19/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1446 - accuracy: 0.8489\n","Epoch 20/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1426 - accuracy: 0.8511\n","Epoch 21/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1410 - accuracy: 0.8511\n","Epoch 22/100\n","470/470 [==============================] - 0s 151us/sample - loss: 0.1396 - accuracy: 0.8532\n","Epoch 23/100\n","470/470 [==============================] - 0s 152us/sample - loss: 0.1334 - accuracy: 0.8447\n","Epoch 24/100\n","470/470 [==============================] - 0s 155us/sample - loss: 0.1362 - accuracy: 0.8489\n","Epoch 25/100\n","470/470 [==============================] - 0s 165us/sample - loss: 0.1422 - accuracy: 0.8511\n","Epoch 26/100\n","470/470 [==============================] - 0s 140us/sample - loss: 0.1407 - accuracy: 0.8489\n","Epoch 27/100\n","470/470 [==============================] - 0s 142us/sample - loss: 0.1387 - accuracy: 0.8532\n","Epoch 28/100\n","470/470 [==============================] - 0s 158us/sample - loss: 0.1387 - accuracy: 0.8489\n","Epoch 29/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1339 - accuracy: 0.8511\n","Epoch 30/100\n","470/470 [==============================] - 0s 133us/sample - loss: 0.1376 - accuracy: 0.8511\n","Epoch 31/100\n","470/470 [==============================] - 0s 137us/sample - loss: 0.1349 - accuracy: 0.8511\n","Epoch 32/100\n","470/470 [==============================] - 0s 162us/sample - loss: 0.1296 - accuracy: 0.8532\n","Epoch 33/100\n","470/470 [==============================] - 0s 156us/sample - loss: 0.1283 - accuracy: 0.8511\n","Epoch 34/100\n","470/470 [==============================] - 0s 144us/sample - loss: 0.1321 - accuracy: 0.8489\n","Epoch 35/100\n","470/470 [==============================] - 0s 161us/sample - loss: 0.1411 - accuracy: 0.8532\n","Epoch 36/100\n","470/470 [==============================] - 0s 159us/sample - loss: 0.1388 - accuracy: 0.8511\n","Epoch 37/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1369 - accuracy: 0.8489\n","Epoch 38/100\n","470/470 [==============================] - 0s 143us/sample - loss: 0.1372 - accuracy: 0.8468\n","Epoch 39/100\n","470/470 [==============================] - 0s 157us/sample - loss: 0.1333 - accuracy: 0.8511\n","Epoch 40/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1290 - accuracy: 0.8511\n","Epoch 41/100\n","470/470 [==============================] - 0s 151us/sample - loss: 0.1276 - accuracy: 0.8511\n","Epoch 42/100\n","470/470 [==============================] - 0s 143us/sample - loss: 0.1383 - accuracy: 0.8532\n","Epoch 43/100\n","470/470 [==============================] - 0s 163us/sample - loss: 0.1367 - accuracy: 0.8532\n","Epoch 44/100\n","470/470 [==============================] - 0s 158us/sample - loss: 0.1317 - accuracy: 0.8532\n","Epoch 45/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1327 - accuracy: 0.8553\n","Epoch 46/100\n","470/470 [==============================] - 0s 143us/sample - loss: 0.1259 - accuracy: 0.8511\n","Epoch 47/100\n","470/470 [==============================] - 0s 145us/sample - loss: 0.1258 - accuracy: 0.8553\n","Epoch 48/100\n","470/470 [==============================] - 0s 141us/sample - loss: 0.1359 - accuracy: 0.8532\n","Epoch 49/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1329 - accuracy: 0.8426\n","Epoch 50/100\n","470/470 [==============================] - 0s 171us/sample - loss: 0.1362 - accuracy: 0.8489\n","Epoch 51/100\n","470/470 [==============================] - 0s 142us/sample - loss: 0.1400 - accuracy: 0.8511\n","Epoch 52/100\n","470/470 [==============================] - 0s 152us/sample - loss: 0.1407 - accuracy: 0.8511\n","Epoch 53/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1373 - accuracy: 0.8511\n","Epoch 54/100\n","470/470 [==============================] - 0s 160us/sample - loss: 0.1314 - accuracy: 0.8426\n","Epoch 55/100\n","470/470 [==============================] - 0s 147us/sample - loss: 0.1305 - accuracy: 0.8532\n","Epoch 56/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1303 - accuracy: 0.8574\n","Epoch 57/100\n","470/470 [==============================] - 0s 145us/sample - loss: 0.1338 - accuracy: 0.8511\n","Epoch 58/100\n","470/470 [==============================] - 0s 155us/sample - loss: 0.1364 - accuracy: 0.8532\n","Epoch 59/100\n","470/470 [==============================] - 0s 138us/sample - loss: 0.1280 - accuracy: 0.8489\n","Epoch 60/100\n","470/470 [==============================] - 0s 151us/sample - loss: 0.1321 - accuracy: 0.8532\n","Epoch 61/100\n","470/470 [==============================] - 0s 149us/sample - loss: 0.1405 - accuracy: 0.8511\n","Epoch 62/100\n","470/470 [==============================] - 0s 142us/sample - loss: 0.1226 - accuracy: 0.8553\n","Epoch 63/100\n","470/470 [==============================] - 0s 135us/sample - loss: 0.1402 - accuracy: 0.8447\n","Epoch 64/100\n","470/470 [==============================] - 0s 165us/sample - loss: 0.1388 - accuracy: 0.8532\n","Epoch 65/100\n","470/470 [==============================] - 0s 149us/sample - loss: 0.1366 - accuracy: 0.8574\n","Epoch 66/100\n","470/470 [==============================] - 0s 136us/sample - loss: 0.1344 - accuracy: 0.8596\n","Epoch 67/100\n","470/470 [==============================] - 0s 154us/sample - loss: 0.1246 - accuracy: 0.8617\n","Epoch 68/100\n","470/470 [==============================] - 0s 160us/sample - loss: 0.1264 - accuracy: 0.8574\n","Epoch 69/100\n","470/470 [==============================] - 0s 145us/sample - loss: 0.1292 - accuracy: 0.8532\n","Epoch 70/100\n","470/470 [==============================] - 0s 135us/sample - loss: 0.1306 - accuracy: 0.8511\n","Epoch 71/100\n","470/470 [==============================] - 0s 167us/sample - loss: 0.1290 - accuracy: 0.8574\n","Epoch 72/100\n","470/470 [==============================] - 0s 139us/sample - loss: 0.1282 - accuracy: 0.8426\n","Epoch 73/100\n","470/470 [==============================] - 0s 167us/sample - loss: 0.1245 - accuracy: 0.8596\n","Epoch 74/100\n","470/470 [==============================] - 0s 142us/sample - loss: 0.1231 - accuracy: 0.8532\n","Epoch 75/100\n","470/470 [==============================] - 0s 141us/sample - loss: 0.1228 - accuracy: 0.8574\n","Epoch 76/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1218 - accuracy: 0.8532\n","Epoch 77/100\n","470/470 [==============================] - 0s 144us/sample - loss: 0.1249 - accuracy: 0.8574\n","Epoch 78/100\n","470/470 [==============================] - 0s 161us/sample - loss: 0.1341 - accuracy: 0.8489\n","Epoch 79/100\n","470/470 [==============================] - 0s 139us/sample - loss: 0.1318 - accuracy: 0.8511\n","Epoch 80/100\n","470/470 [==============================] - 0s 150us/sample - loss: 0.1316 - accuracy: 0.8468\n","Epoch 81/100\n","470/470 [==============================] - 0s 140us/sample - loss: 0.1210 - accuracy: 0.8574\n","Epoch 82/100\n","470/470 [==============================] - 0s 160us/sample - loss: 0.1229 - accuracy: 0.8553\n","Epoch 83/100\n","470/470 [==============================] - 0s 138us/sample - loss: 0.1234 - accuracy: 0.8553\n","Epoch 84/100\n","470/470 [==============================] - 0s 144us/sample - loss: 0.1236 - accuracy: 0.8468\n","Epoch 85/100\n","470/470 [==============================] - 0s 131us/sample - loss: 0.1277 - accuracy: 0.8489\n","Epoch 86/100\n","470/470 [==============================] - 0s 157us/sample - loss: 0.1254 - accuracy: 0.8553\n","Epoch 87/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1310 - accuracy: 0.8553\n","Epoch 88/100\n","470/470 [==============================] - 0s 193us/sample - loss: 0.1220 - accuracy: 0.8511\n","Epoch 89/100\n","470/470 [==============================] - 0s 146us/sample - loss: 0.1202 - accuracy: 0.8532\n","Epoch 90/100\n","470/470 [==============================] - 0s 145us/sample - loss: 0.1233 - accuracy: 0.8553\n","Epoch 91/100\n","470/470 [==============================] - 0s 143us/sample - loss: 0.1194 - accuracy: 0.8553\n","Epoch 92/100\n","470/470 [==============================] - 0s 140us/sample - loss: 0.1174 - accuracy: 0.8574\n","Epoch 93/100\n","470/470 [==============================] - 0s 148us/sample - loss: 0.1376 - accuracy: 0.8447\n","Epoch 94/100\n","470/470 [==============================] - 0s 143us/sample - loss: 0.1321 - accuracy: 0.8596\n","Epoch 95/100\n","470/470 [==============================] - 0s 137us/sample - loss: 0.1300 - accuracy: 0.8638\n","Epoch 96/100\n","470/470 [==============================] - 0s 150us/sample - loss: 0.1215 - accuracy: 0.8511\n","Epoch 97/100\n","470/470 [==============================] - 0s 138us/sample - loss: 0.1236 - accuracy: 0.8553\n","Epoch 98/100\n","470/470 [==============================] - 0s 137us/sample - loss: 0.1318 - accuracy: 0.8489\n","Epoch 99/100\n","470/470 [==============================] - 0s 157us/sample - loss: 0.1250 - accuracy: 0.8617\n","Epoch 100/100\n","470/470 [==============================] - 0s 153us/sample - loss: 0.1213 - accuracy: 0.8617\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3ad01ef4e0>"]},"metadata":{"tags":[]},"execution_count":8}]}]}